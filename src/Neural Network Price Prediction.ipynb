{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wowTokenAppendedData = []\n",
    "regions = ['NA', 'EU', 'CN', 'KR', 'TW']\n",
    "\n",
    "for entry in os.scandir('./input/wowtoken'):\n",
    "    if entry.is_file():\n",
    "        wowTokenEntry = pd.read_csv(entry.path)\n",
    "        wowTokenEntry['region'] = (os.path.splitext(entry.name)[0])\n",
    "        wowTokenEntry['date'] = pd.to_datetime(wowTokenEntry['date'])\n",
    "        wowTokenAppendedData.append(wowTokenEntry)\n",
    "        \n",
    "data = pd.concat(wowTokenAppendedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>region</th>\n",
       "      <th>CN</th>\n",
       "      <th>EU</th>\n",
       "      <th>KR</th>\n",
       "      <th>NA</th>\n",
       "      <th>TW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6835.000000</td>\n",
       "      <td>7744.000000</td>\n",
       "      <td>7642.000000</td>\n",
       "      <td>7886.000000</td>\n",
       "      <td>7468.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>242416.955377</td>\n",
       "      <td>164289.345687</td>\n",
       "      <td>271204.557969</td>\n",
       "      <td>95573.815876</td>\n",
       "      <td>260885.958356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>168907.809419</td>\n",
       "      <td>101425.233611</td>\n",
       "      <td>98936.313849</td>\n",
       "      <td>64075.637750</td>\n",
       "      <td>104487.473796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>48604.000000</td>\n",
       "      <td>30352.000000</td>\n",
       "      <td>121305.000000</td>\n",
       "      <td>18296.000000</td>\n",
       "      <td>114619.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>83650.000000</td>\n",
       "      <td>68769.250000</td>\n",
       "      <td>179645.500000</td>\n",
       "      <td>37004.250000</td>\n",
       "      <td>174211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>215554.000000</td>\n",
       "      <td>171327.000000</td>\n",
       "      <td>285099.500000</td>\n",
       "      <td>89460.500000</td>\n",
       "      <td>213519.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>400670.000000</td>\n",
       "      <td>256468.750000</td>\n",
       "      <td>350899.250000</td>\n",
       "      <td>163553.250000</td>\n",
       "      <td>335554.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>586090.000000</td>\n",
       "      <td>401827.000000</td>\n",
       "      <td>595930.000000</td>\n",
       "      <td>238572.000000</td>\n",
       "      <td>501220.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "region             CN             EU             KR             NA  \\\n",
       "count     6835.000000    7744.000000    7642.000000    7886.000000   \n",
       "mean    242416.955377  164289.345687  271204.557969   95573.815876   \n",
       "std     168907.809419  101425.233611   98936.313849   64075.637750   \n",
       "min      48604.000000   30352.000000  121305.000000   18296.000000   \n",
       "25%      83650.000000   68769.250000  179645.500000   37004.250000   \n",
       "50%     215554.000000  171327.000000  285099.500000   89460.500000   \n",
       "75%     400670.000000  256468.750000  350899.250000  163553.250000   \n",
       "max     586090.000000  401827.000000  595930.000000  238572.000000   \n",
       "\n",
       "region             TW  \n",
       "count     7468.000000  \n",
       "mean    260885.958356  \n",
       "std     104487.473796  \n",
       "min     114619.000000  \n",
       "25%     174211.000000  \n",
       "50%     213519.000000  \n",
       "75%     335554.500000  \n",
       "max     501220.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.pivot(columns='region', values='price').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNA = data.loc[data['region'] == 'NA'].drop(['date', 'region'], axis=1)\n",
    "dataCN = data.loc[data['region'] == 'CN'].drop(['date', 'region'], axis=1)\n",
    "dataEU = data.loc[data['region'] == 'EU'].drop(['date', 'region'], axis=1)\n",
    "dataKR = data.loc[data['region'] == 'KR'].drop(['date', 'region'], axis=1)\n",
    "dataTW = data.loc[data['region'] == 'TW'].drop(['date', 'region'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_short_SMA(prices, period):\n",
    "    if len(prices) < period:\n",
    "        return 0\n",
    "    \n",
    "    return np.mean(prices[-10:])\n",
    "    \n",
    "def calculate_long_SMA(prices, period):\n",
    "    if len(prices) < period:\n",
    "        return 0\n",
    "    \n",
    "    return np.mean(prices[-50:])\n",
    "\n",
    "def calculate_SMAs(data):\n",
    "    prices = data['price'].values\n",
    "    \n",
    "    shortSMAs = []\n",
    "    longSMAs = []\n",
    "    pricesSeen = []\n",
    "    for price in prices:\n",
    "        pricesSeen.append(price)\n",
    "        \n",
    "        shortSMAs.append(calculate_short_SMA(pricesSeen, 10))\n",
    "        longSMAs.append(calculate_long_SMA(pricesSeen, 50))\n",
    "        \n",
    "    data['short_sma'] = shortSMAs\n",
    "    data['long_sma'] = longSMAs\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNA = calculate_SMAs(dataNA)\n",
    "dataCN = calculate_SMAs(dataCN)\n",
    "dataEU = calculate_SMAs(dataEU)\n",
    "dataKR = calculate_SMAs(dataKR)\n",
    "dataTW = calculate_SMAs(dataTW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(data, index):\n",
    "    if index == 0:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        shortSMA = data.loc[index, 'short_sma']\n",
    "        lastShortSMA = data.loc[index-1, 'short_sma']\n",
    "        longSMA = data.loc[index, 'long_sma']\n",
    "        lastLongSMA = data.loc[index-1, 'long_sma']\n",
    "        \n",
    "        if shortSMA > lastShortSMA and longSMA > lastLongSMA:\n",
    "            # Both SMAs are increasing, so the tendency is to rise\n",
    "            return 1\n",
    "\n",
    "        elif shortSMA <= lastShortSMA and longSMA <= lastLongSMA:\n",
    "            # Both SMAs are decreasing, so the tendency is to fall\n",
    "            return 0\n",
    "\n",
    "        elif lastShortSMA <= longSMA and shortSMA > longSMA:\n",
    "            # The short SMA crossed the long SMA by increasing itself, so in this case,\n",
    "            # we hope that the short SMA goes back to the long SMA, so the tendency is to fall\n",
    "            return 0\n",
    "\n",
    "        elif lastShortSMA > longSMA and shortSMA <= longSMA:\n",
    "            # The short SMA crossed the long SMA by decreasing itself, so in this case,\n",
    "            # we hope that the short SMA goes back to the long SMA, so the tendency is to rise\n",
    "            return 1\n",
    "        \n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for index in range(len(dataNA)):\n",
    "    preds.append(make_prediction(dataNA, index))\n",
    "    \n",
    "dataNA['simple_prediction'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "previousPrices = [0]\n",
    "previousPrices.extend(dataNA['price'][:-1])\n",
    "dataNA['previous_price'] = previousPrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "riseOrDecrease = [0]\n",
    "for index in range(len(dataNA['price'])):\n",
    "    if index > 0:\n",
    "        riseOrDecrease.append(1 if dataNA['price'][index] > dataNA['price'][index-1] else 0)\n",
    "dataNA['rise_or_decrease'] = riseOrDecrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>short_sma</th>\n",
       "      <th>long_sma</th>\n",
       "      <th>simple_prediction</th>\n",
       "      <th>previous_price</th>\n",
       "      <th>rise_or_decrease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7876</th>\n",
       "      <td>106512</td>\n",
       "      <td>107315.8</td>\n",
       "      <td>107463.58</td>\n",
       "      <td>0</td>\n",
       "      <td>106678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7877</th>\n",
       "      <td>106376</td>\n",
       "      <td>107151.8</td>\n",
       "      <td>107425.20</td>\n",
       "      <td>0</td>\n",
       "      <td>106512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7878</th>\n",
       "      <td>106238</td>\n",
       "      <td>106985.8</td>\n",
       "      <td>107383.72</td>\n",
       "      <td>0</td>\n",
       "      <td>106376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7879</th>\n",
       "      <td>106106</td>\n",
       "      <td>106825.9</td>\n",
       "      <td>107339.12</td>\n",
       "      <td>0</td>\n",
       "      <td>106238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7880</th>\n",
       "      <td>105973</td>\n",
       "      <td>106660.6</td>\n",
       "      <td>107291.78</td>\n",
       "      <td>0</td>\n",
       "      <td>106106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7881</th>\n",
       "      <td>105905</td>\n",
       "      <td>106505.0</td>\n",
       "      <td>107243.70</td>\n",
       "      <td>0</td>\n",
       "      <td>105973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7882</th>\n",
       "      <td>105987</td>\n",
       "      <td>106373.7</td>\n",
       "      <td>107200.04</td>\n",
       "      <td>0</td>\n",
       "      <td>105905</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7883</th>\n",
       "      <td>106095</td>\n",
       "      <td>106276.4</td>\n",
       "      <td>107162.62</td>\n",
       "      <td>0</td>\n",
       "      <td>105987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7884</th>\n",
       "      <td>106068</td>\n",
       "      <td>106193.8</td>\n",
       "      <td>107128.80</td>\n",
       "      <td>0</td>\n",
       "      <td>106095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7885</th>\n",
       "      <td>106087</td>\n",
       "      <td>106134.7</td>\n",
       "      <td>107101.36</td>\n",
       "      <td>0</td>\n",
       "      <td>106068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price  short_sma   long_sma  simple_prediction  previous_price  \\\n",
       "7876  106512   107315.8  107463.58                  0          106678   \n",
       "7877  106376   107151.8  107425.20                  0          106512   \n",
       "7878  106238   106985.8  107383.72                  0          106376   \n",
       "7879  106106   106825.9  107339.12                  0          106238   \n",
       "7880  105973   106660.6  107291.78                  0          106106   \n",
       "7881  105905   106505.0  107243.70                  0          105973   \n",
       "7882  105987   106373.7  107200.04                  0          105905   \n",
       "7883  106095   106276.4  107162.62                  0          105987   \n",
       "7884  106068   106193.8  107128.80                  0          106095   \n",
       "7885  106087   106134.7  107101.36                  0          106068   \n",
       "\n",
       "      rise_or_decrease  \n",
       "7876                 0  \n",
       "7877                 0  \n",
       "7878                 0  \n",
       "7879                 0  \n",
       "7880                 0  \n",
       "7881                 0  \n",
       "7882                 1  \n",
       "7883                 1  \n",
       "7884                 0  \n",
       "7885                 1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataNA.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(100, input_dim=3, activation='relu'))\n",
    "        self.model.add(Dense(10, activation='relu'))\n",
    "        self.model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "        self.model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "\n",
    "        self.model.summary()\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.model.fit(x_train, y_train, epochs=40, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,421\n",
      "Trainable params: 1,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataNA[['short_sma', 'long_sma', 'previous_price']].values, dataNA['rise_or_decrease'].values, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4226 samples, validate on 1057 samples\n",
      "Epoch 1/40\n",
      "4226/4226 [==============================] - 1s 209us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 2/40\n",
      "4226/4226 [==============================] - 0s 76us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 3/40\n",
      "4226/4226 [==============================] - 0s 72us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 4/40\n",
      "4226/4226 [==============================] - 0s 70us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 5/40\n",
      "4226/4226 [==============================] - 0s 74us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 6/40\n",
      "4226/4226 [==============================] - 0s 75us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 7/40\n",
      "4226/4226 [==============================] - 0s 66us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 8/40\n",
      "4226/4226 [==============================] - 0s 64us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 9/40\n",
      "4226/4226 [==============================] - 0s 70us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 10/40\n",
      "4226/4226 [==============================] - 0s 75us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 11/40\n",
      "4226/4226 [==============================] - 0s 71us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 12/40\n",
      "4226/4226 [==============================] - 0s 66us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 13/40\n",
      "4226/4226 [==============================] - 0s 65us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 14/40\n",
      "4226/4226 [==============================] - 0s 72us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 15/40\n",
      "4226/4226 [==============================] - 0s 71us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 16/40\n",
      "4226/4226 [==============================] - 0s 72us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 17/40\n",
      "4226/4226 [==============================] - 0s 67us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 18/40\n",
      "4226/4226 [==============================] - 0s 69us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 19/40\n",
      "4226/4226 [==============================] - 0s 74us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 20/40\n",
      "4226/4226 [==============================] - 0s 69us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 21/40\n",
      "4226/4226 [==============================] - 0s 70us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 22/40\n",
      "4226/4226 [==============================] - 0s 73us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 23/40\n",
      "4226/4226 [==============================] - 0s 73us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 24/40\n",
      "4226/4226 [==============================] - 0s 67us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 25/40\n",
      "4226/4226 [==============================] - 0s 70us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 26/40\n",
      "4226/4226 [==============================] - 0s 73us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 27/40\n",
      "4226/4226 [==============================] - 0s 70us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 28/40\n",
      "4226/4226 [==============================] - 0s 69us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 29/40\n",
      "4226/4226 [==============================] - 0s 70us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 30/40\n",
      "4226/4226 [==============================] - 0s 69us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 31/40\n",
      "4226/4226 [==============================] - 0s 70us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 32/40\n",
      "4226/4226 [==============================] - 0s 71us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 33/40\n",
      "4226/4226 [==============================] - 0s 71us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 34/40\n",
      "4226/4226 [==============================] - 0s 70us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 35/40\n",
      "4226/4226 [==============================] - 0s 71us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 36/40\n",
      "4226/4226 [==============================] - 0s 72us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 37/40\n",
      "4226/4226 [==============================] - 0s 72us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 38/40\n",
      "4226/4226 [==============================] - 0s 73us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 39/40\n",
      "4226/4226 [==============================] - 0s 72us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n",
      "Epoch 40/40\n",
      "4226/4226 [==============================] - 0s 71us/step - loss: nan - acc: 0.5213 - val_loss: nan - val_acc: 0.5137\n"
     ]
    }
   ],
   "source": [
    "nn.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = nn.model.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
